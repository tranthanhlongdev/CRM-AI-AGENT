========================================
VOICEBOT - WEBRTC VOICE CALL INTEGRATION
========================================

üéôÔ∏è T·ªîNG QUAN
============

Backend ƒë√£ h·ªó tr·ª£ WebRTC signaling ƒë·ªÉ Customer v√† Agent c√≥ th·ªÉ n√≥i chuy·ªán tr·ª±c ti·∫øp qua audio call th·∫≠t s·ª±.

Flow:
1. Customer g·ªçi ‚Üí Backend t√¨m Agent ‚Üí Call connected
2. C·∫£ 2 b√™n join WebRTC room
3. WebRTC signaling exchange (offer/answer/ICE)
4. Audio stream established ‚Üí N√≥i chuy·ªán tr·ª±c ti·∫øp!

üîå BACKEND ƒê√É CUNG C·∫§P
======================

## WebRTC Signaling Events (SocketIO)

### Join/Leave Call Room
- `join_call_room` - Join v√†o room c·ªßa cu·ªôc g·ªçi
- `leave_call_room` - Leave kh·ªèi room
- `peer_joined` - C√≥ peer kh√°c join v√†o
- `peer_left` - Peer kh√°c ƒë√£ leave

### WebRTC Signaling
- `webrtc_offer` - G·ª≠i offer (customer ‚Üí agent)
- `webrtc_answer` - G·ª≠i answer (agent ‚Üí customer)  
- `webrtc_ice_candidate` - Exchange ICE candidates
- `webrtc_media_state` - Tr·∫°ng th√°i media (mute/unmute)

### Response Events
- `webrtc_offer_received` - Nh·∫≠n offer t·ª´ peer
- `webrtc_answer_received` - Nh·∫≠n answer t·ª´ peer
- `webrtc_ice_candidate_received` - Nh·∫≠n ICE candidate
- `peer_media_state` - Tr·∫°ng th√°i media c·ªßa peer

## REST APIs

### WebRTC Configuration
GET /api/webrtc/config
Response:
{
  "iceServers": [
    {"urls": ["stun:stun.l.google.com:19302"]},
    {"urls": ["stun:stun1.l.google.com:19302"]}
  ],
  "mediaConstraints": {
    "audio": {
      "echoCancellation": true,
      "noiseSuppression": true,
      "autoGainControl": true
    },
    "video": false
  }
}

### Call WebRTC Info
GET /api/webrtc/call/{callId}/info
Response:
{
  "callId": "CALL_123",
  "roomName": "call_CALL_123",
  "signalingUrl": "http://localhost:8000",
  "events": {
    "join": "join_call_room",
    "offer": "webrtc_offer",
    "answer": "webrtc_answer",
    "iceCandidate": "webrtc_ice_candidate"
  }
}

üéØ FRONTEND INTEGRATION
=======================

## 1. Setup WebRTC khi Call Connected

```javascript
socket.on('call_connected', async (data) => {
  const { callId, webrtcRoom } = data;
  
  // Join WebRTC room
  socket.emit('join_call_room', {
    callId: callId,
    peerType: 'customer' // ho·∫∑c 'agent'
  });
  
  // Kh·ªüi t·∫°o WebRTC
  await initWebRTC(callId);
});
```

## 2. WebRTC Setup

```javascript
class VoiceCallManager {
  constructor(socket, callId, peerType) {
    this.socket = socket;
    this.callId = callId;
    this.peerType = peerType; // 'customer' ho·∫∑c 'agent'
    this.peerConnection = null;
    this.localStream = null;
    this.remoteStream = null;
    
    this.setupWebRTC();
    this.setupSocketEvents();
  }

  async setupWebRTC() {
    // Get WebRTC config t·ª´ backend
    const configResponse = await fetch('/api/webrtc/config');
    const config = await configResponse.json();
    
    // T·∫°o peer connection
    this.peerConnection = new RTCPeerConnection({
      iceServers: config.data.iceServers
    });

    // Setup events
    this.peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        this.socket.emit('webrtc_ice_candidate', {
          callId: this.callId,
          candidate: event.candidate,
          fromPeer: this.peerType
        });
      }
    };

    this.peerConnection.ontrack = (event) => {
      console.log('Received remote stream');
      this.remoteStream = event.streams[0];
      this.playRemoteAudio();
    };
  }

  async startCall() {
    try {
      // Get user media (microphone)
      this.localStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        },
        video: false
      });

      // Add local stream to peer connection
      this.localStream.getTracks().forEach(track => {
        this.peerConnection.addTrack(track, this.localStream);
      });

      // Customer t·∫°o offer
      if (this.peerType === 'customer') {
        await this.createOffer();
      }

    } catch (error) {
      console.error('Error starting call:', error);
    }
  }

  async createOffer() {
    try {
      const offer = await this.peerConnection.createOffer({
        offerToReceiveAudio: true,
        offerToReceiveVideo: false
      });

      await this.peerConnection.setLocalDescription(offer);

      // G·ª≠i offer qua signaling server
      this.socket.emit('webrtc_offer', {
        callId: this.callId,
        offer: offer,
        fromPeer: this.peerType
      });

    } catch (error) {
      console.error('Error creating offer:', error);
    }
  }

  async handleOffer(offer) {
    try {
      await this.peerConnection.setRemoteDescription(offer);

      // Agent t·∫°o answer
      if (this.peerType === 'agent') {
        const answer = await this.peerConnection.createAnswer();
        await this.peerConnection.setLocalDescription(answer);

        // G·ª≠i answer
        this.socket.emit('webrtc_answer', {
          callId: this.callId,
          answer: answer,
          fromPeer: this.peerType
        });
      }

    } catch (error) {
      console.error('Error handling offer:', error);
    }
  }

  async handleAnswer(answer) {
    try {
      await this.peerConnection.setRemoteDescription(answer);
    } catch (error) {
      console.error('Error handling answer:', error);
    }
  }

  async handleIceCandidate(candidate) {
    try {
      await this.peerConnection.addIceCandidate(candidate);
    } catch (error) {
      console.error('Error handling ICE candidate:', error);
    }
  }

  setupSocketEvents() {
    // Nh·∫≠n offer t·ª´ peer kh√°c
    this.socket.on('webrtc_offer_received', (data) => {
      if (data.callId === this.callId) {
        this.handleOffer(data.offer);
      }
    });

    // Nh·∫≠n answer t·ª´ peer kh√°c
    this.socket.on('webrtc_answer_received', (data) => {
      if (data.callId === this.callId) {
        this.handleAnswer(data.answer);
      }
    });

    // Nh·∫≠n ICE candidate
    this.socket.on('webrtc_ice_candidate_received', (data) => {
      if (data.callId === this.callId) {
        this.handleIceCandidate(data.candidate);
      }
    });

    // Peer joined
    this.socket.on('peer_joined', (data) => {
      if (data.callId === this.callId) {
        console.log('Peer joined:', data.peerType);
        // N·∫øu l√† customer v√† agent v·ª´a join, start call
        if (this.peerType === 'customer' && data.peerType === 'agent') {
          this.startCall();
        }
      }
    });
  }

  playRemoteAudio() {
    const audioElement = document.getElementById('remoteAudio');
    if (audioElement && this.remoteStream) {
      audioElement.srcObject = this.remoteStream;
      audioElement.play();
    }
  }

  mute() {
    if (this.localStream) {
      this.localStream.getAudioTracks().forEach(track => {
        track.enabled = false;
      });
      
      // Th√¥ng b√°o tr·∫°ng th√°i
      this.socket.emit('webrtc_media_state', {
        callId: this.callId,
        peerType: this.peerType,
        audioEnabled: false
      });
    }
  }

  unmute() {
    if (this.localStream) {
      this.localStream.getAudioTracks().forEach(track => {
        track.enabled = true;
      });
      
      this.socket.emit('webrtc_media_state', {
        callId: this.callId,
        peerType: this.peerType,
        audioEnabled: true
      });
    }
  }

  endCall() {
    // Stop local stream
    if (this.localStream) {
      this.localStream.getTracks().forEach(track => track.stop());
    }

    // Close peer connection
    if (this.peerConnection) {
      this.peerConnection.close();
    }

    // Leave WebRTC room
    this.socket.emit('leave_call_room', {
      callId: this.callId,
      peerType: this.peerType
    });
  }
}
```

## 3. Integration v·ªõi Softphone

```javascript
class VoiceBotSoftphone {
  constructor() {
    this.socket = io('http://localhost:8000');
    this.voiceCallManager = null;
    this.setupEvents();
  }

  setupEvents() {
    this.socket.on('call_connected', async (data) => {
      console.log('Call connected, starting voice call...');
      
      // Kh·ªüi t·∫°o voice call manager
      this.voiceCallManager = new VoiceCallManager(
        this.socket, 
        data.callId, 
        'customer'
      );

      // Join WebRTC room
      this.socket.emit('join_call_room', {
        callId: data.callId,
        peerType: 'customer'
      });

      // Start call khi agent join
      await this.voiceCallManager.startCall();
    });

    this.socket.on('call_ended', () => {
      if (this.voiceCallManager) {
        this.voiceCallManager.endCall();
        this.voiceCallManager = null;
      }
    });
  }

  makeCall(phoneNumber) {
    this.socket.emit('make_call', {
      callerNumber: phoneNumber,
      calledNumber: '1900'
    });
  }

  endCall() {
    if (this.voiceCallManager) {
      this.voiceCallManager.endCall();
    }
    // ... existing end call logic
  }

  mute() {
    if (this.voiceCallManager) {
      this.voiceCallManager.mute();
    }
  }

  unmute() {
    if (this.voiceCallManager) {
      this.voiceCallManager.unmute();
    }
  }
}
```

## 4. Integration v·ªõi Agent Dashboard

```javascript
class AgentDashboard {
  constructor() {
    this.socket = io('http://localhost:8000');
    this.voiceCallManager = null;
    this.setupEvents();
  }

  setupEvents() {
    this.socket.on('incoming_call', (data) => {
      this.showIncomingCallModal(data);
    });

    this.socket.on('call_answered', async (data) => {
      console.log('Call answered, preparing voice call...');
      
      // Kh·ªüi t·∫°o voice call manager cho agent
      this.voiceCallManager = new VoiceCallManager(
        this.socket, 
        data.call.callId, 
        'agent'
      );

      // Join WebRTC room
      this.socket.emit('join_call_room', {
        callId: data.call.callId,
        peerType: 'agent'
      });

      // Agent ch·ªù offer t·ª´ customer
      await this.voiceCallManager.startCall();
    });
  }

  answerCall(callId) {
    this.socket.emit('answer_call', {
      callId: callId,
      agentId: this.agentId
    });
  }
}
```

## 5. HTML Audio Elements

```html
<!-- Th√™m v√†o HTML -->
<audio id="remoteAudio" autoplay></audio>

<!-- Call controls -->
<div id="callControls" style="display: none;">
  <button onclick="muteCall()">üîá Mute</button>
  <button onclick="unmuteCall()">üîä Unmute</button>
  <button onclick="endCall()">üì¥ End Call</button>
</div>
```

üîß TROUBLESHOOTING
==================

## Common Issues:

1. **Microphone Permission**
   ```javascript
   // Check permissions
   navigator.permissions.query({name: 'microphone'}).then((result) => {
     console.log('Microphone permission:', result.state);
   });
   ```

2. **No Audio**
   - Check browser microphone permissions
   - Verify audio element autoplay attribute
   - Check WebRTC connection state

3. **Connection Failed**
   - Verify STUN servers connectivity
   - Check firewall/NAT settings
   - Monitor ICE connection state

## Debug Commands:

```javascript
// Check connection state
console.log('Connection state:', peerConnection.connectionState);
console.log('ICE connection state:', peerConnection.iceConnectionState);

// Check audio tracks
console.log('Local tracks:', localStream.getTracks());
console.log('Remote tracks:', remoteStream.getTracks());
```

üìã BROWSER SUPPORT
==================

- Chrome/Edge: Full support ‚úÖ
- Firefox: Full support ‚úÖ  
- Safari: Partial support ‚ö†Ô∏è
- Mobile browsers: Limited support ‚ö†Ô∏è

Recommend: Chrome/Firefox for best experience

üöÄ PRODUCTION NOTES
===================

1. **HTTPS Required**: WebRTC needs HTTPS in production
2. **TURN Servers**: Add TURN servers for NAT traversal
3. **Audio Quality**: Configure audio codecs (Opus recommended)
4. **Error Handling**: Implement comprehensive error handling
5. **Fallback**: Provide fallback for unsupported browsers

========================================
VOICE CALL READY! üéôÔ∏èüìû
========================================

Backend ƒë√£ s·∫µn s√†ng h·ªó tr·ª£ voice call th·∫≠t s·ª±!
Frontend c·∫ßn implement WebRTC client theo h∆∞·ªõng d·∫´n tr√™n.
